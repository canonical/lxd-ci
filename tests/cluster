#!/bin/bash
set -eux

# Install LXD
install_lxd

# Configure LXD
lxd init --auto --storage-backend=btrfs

IMAGE="${TEST_IMG:-ubuntu-minimal-daily:24.04}"
SIZE="$1"

if [ -z "${1:-""}" ] || [ -z "${2:-""}" ] || [ -z "${3:-""}" ]; then
    echo "Usage: ${0} <count> <source channel> <destination channel>"
    exit 1
fi

echo "==> Deploying the cluster"

print_log() {
    echo "==> Start log file ${1}"
    log_file="${1}.log"
    lxc file pull "${1}/var/snap/lxd/common/lxd/logs/lxd.log" "${log_file}" || true
    cat "${log_file}" || true
    echo "<== End log file ${1}"
    rm -f "${log_file}"
}

# wait for u1 and u2 to be booted and have u1 and m1 probe u2's IPv4
instance_connectivity_checks() {
    lxc exec m1 -- sh -c "$(declare -f waitInstanceReady waitInstanceBooted); waitInstanceBooted u1"
    lxc exec m1 -- sh -c "$(declare -f waitInstanceReady waitInstanceBooted); waitInstanceBooted u2"
    lxc exec m1 -- lxc list
    U2_IPV4="$(lxc exec m1 -- lxc list u2 -c4 --format=csv | cut -d' ' -f1)"
    # XXX: replace ping (not on -minimal images) by a TCP probe on ssh port
    lxc exec m1 -- lxc exec u1 -- timeout 30s bash -c "grep -m1 ^SSH < /dev/tcp/${U2_IPV4}/22"
    lxc exec m1 -- timeout 30s bash -c "grep -m1 ^SSH < /dev/tcp/${U2_IPV4}/22"
}

wait_for_online_cluster() {
    sleep 5
    for i in $(seq "${SIZE}"); do
        lxc exec "m${i}" -- lxd waitready --timeout=300
    done
    for _ in $(seq 30); do
        ONLINE_MEMBERS="$(lxc exec m1 -- lxc cluster list | grep -cwF ONLINE || true)"
        [ "${ONLINE_MEMBERS}" = "${SIZE}" ] && break
        sleep 5
    done
    sleep 5
}

# Launch the container
lxc launch "${IMAGE}" m1 -c security.nesting=true -c security.devlxd.images=true

waitInstanceBooted m1

# XXX: not using `--cohort=+` as this is an older LXD that will be upgraded later on
lxc exec m1 -- snap install lxd --channel="$2" || lxc exec m1 -- snap refresh lxd --channel="$2"

lxc pause m1
for i in $(seq 2 "${SIZE}"); do
    lxc copy m1 "m${i}"
    lxc start "m${i}"
    waitInstanceBooted "m${i}"
done
lxc start m1

for i in $(seq "${SIZE}"); do
    sleep 10

    # Configure the cluster
    if [ "$i" = "1" ]; then
        CLUSTER_IP=$(lxc exec "m${i}" -- ip -4 addr show dev eth0 scope global | grep inet | cut -d' ' -f6 | cut -d/ -f1)
        lxc exec "m${i}" -- lxc config set core.https_address "${CLUSTER_IP}:8443"
        lxc exec "m${i}" -- lxc config set cluster.https_address "${CLUSTER_IP}:8443"
        lxc exec "m${i}" -- lxc cluster enable "m${i}"
        lxc exec "m${i}" -- lxc network create lxdfan0 bridge.mode=fan
        lxc exec "m${i}" -- lxc storage create default dir
        lxc exec "m${i}" -- lxc profile device add default root disk path=/ pool=default
        lxc exec "m${i}" -- lxc profile device add default eth0 nic name=eth0 network=lxdfan0
        lxc exec "m${i}" -- lxc network show lxdfan0
        CLUSTER_CRT=$(lxc file pull "m${i}"/var/snap/lxd/common/lxd/cluster.crt - | sed ':a;N;$!ba;s/\n/\n\n/g')
    else
        MEMBER_IP=$(lxc exec "m${i}" -- ip -4 addr show dev eth0 scope global | grep inet | cut -d' ' -f6 | cut -d/ -f1)

        # Get a join token
        if echo "${LXD_SNAP_CHANNEL}" | grep -qE "^4\.0/"; then
            # 4.0 doesn't support --quiet
            TOKEN="$(lxc exec m1 -- lxc cluster add "m${i}" | tail -n1)"
        else
            TOKEN="$(lxc exec m1 -- lxc cluster add --quiet "m${i}")"
        fi

        lxc exec "m${i}" -- lxd init --preseed << EOF
cluster:
  server_name: "m${i}"
  enabled: true
  member_config: []
  cluster_address: ${CLUSTER_IP}:8443
  cluster_certificate: "${CLUSTER_CRT}"
  server_address: ${MEMBER_IP}:8443
  cluster_token: "${TOKEN}"
EOF
    fi
done

echo "==> Validating the cluster"
lxc exec m1 -- lxc info
lxc exec m1 -- lxc cluster list

echo "==> Create test instances"
for i in 1 2; do
  lxc exec m1 -- lxc launch "${IMAGE}" u"${i}"
  lxc exec m1 -- sh -c "$(declare -f waitInstanceReady); waitInstanceReady u${i}"
  # Apparmor fails to start (`/sbin/apparmor_parser: Access denied. You need
  # policy admin privileges to manage profiles.`) in nested containers which
  # cascades to snapd as it requires Apparmor to be functional
  lxc exec m1 -- lxc exec u"${i}" -- systemctl mask --now apparmor.service snapd.seeded.service snapd.service snapd.socket
  lxc exec m1 -- lxc exec u"${i}" -- systemctl reset-failed apparmor.service snapd.seeded.service snapd.service snapd.socket
done

# Test fan networking (intra fan from container and host, as well as external NAT comms)
echo "==> Test fan networking"
instance_connectivity_checks

tmp_cert_dir="$(mktemp -d)"

if hasNeededAPIExtension certificate_project; then
    TEST_RESTRICTED=1
else
    echo "Skipping restricted certificate test, not supported"
    TEST_RESTRICTED=0
fi

echo "==> Add unrestricted certificate"
createCertificateAndKey "${tmp_cert_dir}/cert.key" "${tmp_cert_dir}/cert.crt" "cert.local"
lxc config trust add "${tmp_cert_dir}/cert.crt"
unrestricted_fingerprint="$(certificateFingerprintShort "${tmp_cert_dir}/cert.crt")"

if [ "${TEST_RESTRICTED}" = "1" ]; then
  echo "==> Add restricted certificate"
  createCertificateAndKey "${tmp_cert_dir}/cert-restricted.key" "${tmp_cert_dir}/cert-restricted.crt" "cert-restricted.local"
  lxc config trust add "${tmp_cert_dir}/cert-restricted.crt" --restricted --projects default
  restricted_fingerprint="$(certificateFingerprintShort "${tmp_cert_dir}/cert-restricted.crt")"
fi

echo "==> Check the certificates for their permissions"
lxc query "/1.0/certificates/${unrestricted_fingerprint}" | jq -er '.restricted == false'
lxc query "/1.0/certificates/${unrestricted_fingerprint}" | jq -er '.type == "client"'

if [ "${TEST_RESTRICTED}" = "1" ]; then
  lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.restricted == true'
  lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.type == "client"'
  lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.projects[0] == "default"'
fi

if [ "${TEST_RESTRICTED}" = "1" ]; then
  echo "==> Add restricted and unrestricted metrics certificates"
  createCertificateAndKey "${tmp_cert_dir}/metrics.key" "${tmp_cert_dir}/metrics.crt" "metrics.local"
  createCertificateAndKey "${tmp_cert_dir}/metrics-restricted.key" "${tmp_cert_dir}/metrics-restricted.crt" "metrics-restricted.local"
  lxc config trust add "${tmp_cert_dir}/metrics.crt" --type metrics
  lxc config trust add "${tmp_cert_dir}/metrics-restricted.crt" --type metrics --restricted --projects default
  unrestricted_metrics_fingerprint="$(certificateFingerprintShort "${tmp_cert_dir}/metrics.crt")"
  restricted_metrics_fingerprint="$(certificateFingerprintShort "${tmp_cert_dir}/metrics-restricted.crt")"

  echo "==> Check the metrics certificates for its permissions"
  lxc query "/1.0/certificates/${unrestricted_metrics_fingerprint}" | jq -er '.restricted == false'
  lxc query "/1.0/certificates/${unrestricted_metrics_fingerprint}" | jq -er '.type == "metrics"'
  lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.restricted == true'
  lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.type == "metrics"'
  lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.projects[0] == "default"'
fi

echo "==> Upgrading the cluster"
for i in $(seq "${SIZE}"); do
    lxc exec "m${i}" -- snap wait system seed.loaded
    lxc exec "m${i}" -- snap refresh
    # XXX: there should be no refresh ongoing but we've seen races before so let's collect evidences
    lxc exec "m${i}" -- snap changes
    lxc exec "m${i}" -- snap switch lxd --channel="$3" --cohort=+
    if [ "$i" = "${SIZE}" ]; then
        lxc exec "m${i}" -- timeout 10m snap refresh lxd
    fi
done

echo "==> Wait for all members to be ONLINE"
wait_for_online_cluster

echo "==> Validating the cluster"
lxc exec m1 -- lxc info
lxc exec m1 -- lxc cluster list

echo "==> Verify that instances are still functional after the cluster upgrade"
instance_connectivity_checks

echo "==> Restarting the cluster"
lxc restart --all
wait_for_online_cluster

echo "==> Verify that instances are still functional after the cluster reboot"
instance_connectivity_checks

echo "==> Check the certificates for its permissions after cluster upgrade"
lxc query "/1.0/certificates/${unrestricted_fingerprint}" | jq -er '.restricted == false'
lxc query "/1.0/certificates/${unrestricted_fingerprint}" | jq -er '.type == "client"'
if [ "${TEST_RESTRICTED}" = "1" ]; then
    lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.restricted == true'
    lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.type == "client"'
    lxc query "/1.0/certificates/${restricted_fingerprint}" | jq -er '.projects[0] == "default"'
fi

if [ "${TEST_RESTRICTED}" = "1" ]; then
    echo "==> Check the metrics certificates for its permissions after cluster upgrade"
    lxc query "/1.0/certificates/${unrestricted_metrics_fingerprint}" | jq -er '.restricted == false'
    lxc query "/1.0/certificates/${unrestricted_metrics_fingerprint}" | jq -er '.type == "metrics"'
    lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.restricted == true'
    lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.type == "metrics"'
    lxc query "/1.0/certificates/${restricted_metrics_fingerprint}" | jq -er '.projects[0] == "default"'
fi

echo "==> Check container can be stopped after upgrade (checks for stop hook notification functionality)"
lxc exec m1 -- lxc stop --force u1
lxc exec m1 -- lxc stop --force u2

echo "==> Deleting the cluster"
for i in $(seq "${SIZE}"); do
    print_log "m${i}"
    lxc delete --force "m${i}"
done

rm -rf "${tmp_cert_dir}"

# shellcheck disable=SC2034
FAIL=0
